{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Manipulate data the MXNet way with NDArray\n",
    "\n",
    "MXNet's NDArray provides a data structure similar to NumPy's multi-dimensional array, adding some key capabilities. First, NDArrays support asynchronous computation on CPU, GPU, and distributed cloud architectures. Second, they provide support for automatic differentiation. These properties make it an ideal library for machine learning both for research projects and production systems.\n",
    "\n",
    "\n",
    "## Getting started\n",
    "\n",
    "First, let's import ``mxnet`` and (for convenience) ``mxnet.ndarray``, the only dependencies we'll need in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import mxnet.ndarray as nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's see how to create an NDArray, without initializing values. Speficially we'll create a 2D array (also called a *matrix*) with 6 rows and 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.00000000e+00  -0.00000000e+00  -1.12447217e-19  -2.85864887e-42]\n",
      " [  8.40779079e-45   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   4.57523949e-41   1.87544948e+28   1.03964458e-05]\n",
      " [  3.25370380e+21   1.04132675e-11   3.36446871e+21   4.22486810e-05]\n",
      " [  6.70030531e-10   7.98834428e+20   1.03939814e+21   3.41820942e-06]\n",
      " [  4.16550197e-11   7.14495034e+31   4.14181787e-41   5.51012977e-40]]\n",
      "<NDArray 6x4 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "x = nd.empty(shape=(6,4))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we'll want create arrays whose values are sampled randomly. This is especially common when we intend to use the array as a parameter in a neural network. In this snipped, we initialize with values drawn from a standard normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.57344317  1.26625562 -0.14007865  0.89506418]\n",
      " [ 0.29670078 -0.60159451  1.31119514  1.20405591]\n",
      " [ 0.5035904  -0.9712193  -1.18944502 -0.58256227]\n",
      " [-0.55021369  0.37170771 -1.59187555  0.93000722]\n",
      " [-1.10819459 -1.42257547  0.07872018 -0.51761991]\n",
      " [-0.91856349  2.00883245 -0.74571455  0.2863085 ]]\n",
      "<NDArray 6x4 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "x = nd.random_normal(shape=(6,4))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in NumPy, the dimensions of each NDArray are accessible via the ``.shape`` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 4)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also query its size, which is equal to the product of the components of the shape. Together with the precision of the stored values, this tells us how much memory the array occupies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "print(x.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations\n",
    "\n",
    "NDarray supports a large number of standard mathematical operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.78152943  1.82671511  1.67394257  1.86482394]\n",
      " [-1.22604227 -1.13013196 -1.20404983 -0.68503404]\n",
      " [-0.85134214 -0.31642807 -2.14692903 -1.03737545]\n",
      " [-1.27506936  0.69681579 -0.47991192 -0.37022686]\n",
      " [-1.58646703 -1.05464101 -1.09522903  0.93580633]\n",
      " [-1.7107482   2.25037408  0.18638974  0.76528859]]\n",
      "<NDArray 6x4 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "y = nd.random_normal(shape=(6,4))\n",
    "c = x + y\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-place operations\n",
    "\n",
    "In the previous example, we allocated new memory for the sum ``x+y`` and assigned a reference to the variable ``c``. To make better use of memory, we often prefer to perform operations in place, reusing already allocated memory. \n",
    "\n",
    "In MXNet, we can specify where to write the results of operations by assigning them with slice notation, e.g., ``result[:] = ...``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.78152943  1.82671511  1.67394257  1.86482394]\n",
      " [-1.22604227 -1.13013196 -1.20404983 -0.68503404]\n",
      " [-0.85134214 -0.31642807 -2.14692903 -1.03737545]\n",
      " [-1.27506936  0.69681579 -0.47991192 -0.37022686]\n",
      " [-1.58646703 -1.05464101 -1.09522903  0.93580633]\n",
      " [-1.7107482   2.25037408  0.18638974  0.76528859]]\n",
      "<NDArray 6x4 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "result = nd.zeros(shape=(6,4))\n",
    "result[:] = x+y\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're not planning to re-use ``x``, then we can assign the result to ``x`` itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x[:] = x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But be careful! This is **NOT** the same as ``x = x + y``. If we don't use slice notation then we allocate new memory and assign a reference to the new data to the variable ``x``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing\n",
    "\n",
    "MXNet NDArrays support slicing in all the ridiculous ways you might imagine accessing your data. Here's an example of reading the second and third rows from ``x``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.85134214 -0.31642807 -2.14692903 -1.03737545]\n",
       " [-1.27506936  0.69681579 -0.47991192 -0.37022686]]\n",
       "<NDArray 2x4 @cpu(0)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Now let's try whiting to a specific element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -0.55021369   5.           9.          12.34566975]\n",
      "<NDArray 4 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "x[3,2] = 9.0\n",
    "print(x[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weird multi-dimensional slicing\n",
    "\n",
    "We can even write to arbitrary ranges along each of the axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.57344317   1.26625562  -0.14007865   0.89506418]\n",
      " [  0.29670078  -0.60159451   1.31119514   1.20405591]\n",
      " [  0.5035904    5.           5.          -0.58256227]\n",
      " [ -0.55021369   5.           5.          12.34566975]\n",
      " [ -1.10819459  -1.42257547   0.07872018  -0.51761991]\n",
      " [ -0.91856349   2.00883245  -0.74571455   0.2863085 ]]\n",
      "<NDArray 6x4 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "x[2:4,1:3] = 5.0\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting from MXNet NDArray to NumPy \n",
    "\n",
    "Converting MXNet NDArrays to and from NumPy is easy. Note that, unlike in PyTorch, the converted arrays do not share memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.]\n",
      "<NDArray 5 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "a = nd.ones(shape=(5))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.asnumpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  1.  1.  1.  1.]\n",
      "[ 1.  1.  1.  1.  1.]\n",
      "<NDArray 5 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "b[0] = 2\n",
    "print(b)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting from NumPy Array to MXNet NDArray\n",
    "\n",
    "Constructing an MXNet NDarray from a NumPy Array is straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  1.  1.  1.  1.]\n",
      "<NDArray 5 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "c = nd.array(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing context\n",
    "\n",
    "In MXNet, every array has a context. One context could be the CPU. Other contexts might be various GPUs. Things can get even hairier when we deploy jobs across multiple servers. By assigning arrays to contexts intelligently, we can minimize the time spent transferring data between devices. For example, when training neural networks on a server with a GPU, we typically prefer for the model's parameters to live on the GPU. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = nd.array(b, mx.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an NDArray on a given context, we can copy it to another context by using the ``copyto()`` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  1.  1.  1.  1.]\n",
      "<NDArray 5 @cpu(1)>\n"
     ]
    }
   ],
   "source": [
    "e = d.copyto(mx.cpu(1))\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watch out!\n",
    "\n",
    "Imagine that your variable ``d`` already lives on your second GPU (``mx.gpu(1)``). What happens if we call ``d.copyto(mx.gpu(1))``? It will make a copy and allocate new memory, even though that variable already lives on the desired device! \n",
    "\n",
    "Often, we only want to make a copy if the variable *currently* lives in the wrong context. In these cases, we can call ``as_in_context()``. If the variable is already on ``mx.gpu(1)`` then this is a no-op."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  1.  1.  1.  1.]\n",
      "<NDArray 5 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "f = d.as_in_context(mx.cpu(0))\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For whinges or inquiries, [open an issue on  GitHub.](https://github.com/zackchase/mxnet-the-straight-dope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
