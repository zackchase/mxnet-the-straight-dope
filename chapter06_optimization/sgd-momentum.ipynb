{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic gradient descent with momentum\n",
    "\n",
    "## What can go wrong with gradient descent\n",
    "\n",
    "As discussed in the [previous chapter](./gd-sgd.ipynb), at each iteration gradient descent finds the direction where the objective function can be reduced fastest. Thus, gradient descent is also known as the method of steepest descent. Essentially, gradient descent is a greedy algorithm. What can go wrong with it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivating example\n",
    "\n",
    "For better visualuzation, let us consider a quadratic loss function $f: \\mathbb{R}^2 \\rightarrow \\mathbb{R}$ taking a two-dimension vector $\\mathbf{x} = [x_1, x_2]^\\top$ as the input. In the following figure, the contour lines indicate the value of $f(\\mathbf{x})$. The triangle indicates the starting point of gradient descent's search path for the solution to the optimization problem. The search path is indicated by the arrows in the figure. Clearly, gradient descent wastes too much time swinging back and forth along the direction in parallel with the $x_2$-axis while advancing too slowly along the direction of the $x_1$-axis.\n",
    "\n",
    "You may wonder, what causes this problem?\n",
    "\n",
    "![](../img/gd-move.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curvature and Hessian matrix\n",
    "\n",
    "Before discussing the issues with gradient descent, let us take a moment to describe curvature and Hessian matrix of objective functions.\n",
    "\n",
    "In one-dimension domain, a second derivative of a function indicates how fast the first derivative changes when the input changes. Thus, it is often considered as a measure of the **curvature** of a function. \n",
    "\n",
    "Consider the objective function $f: \\mathbb{R}^d \\rightarrow \\mathbb{R}$ that takes any multi-dimensional vector $\\mathbf{x} = [x_1, x_2, \\ldots, x_d]^\\top$ as the input. Its **Hessian matrix** $\\mathbf{H} \\in \\mathbb{R}^{d \\times d}$ collects its second derivatives with respect to different combinations of inputs and is defined as\n",
    "\n",
    "$$\\mathbf{H}_{i,j} = \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_i \\partial x_j}$$\n",
    "\n",
    "for all $i, j = 1, \\ldots, d$. Since $\\mathbf{H}$ is a real symmetric matrix, by spectral theorem, it is orthogonally diagonalizable as\n",
    "\n",
    "$$ \\mathbf{S}^\\top \\mathbf{H} \\mathbf{S} =  \\mathbf{\\Lambda},$$\n",
    "\n",
    "where $\\mathbf{S}$ is an orthornomal eigenbasis composed of eigenvectors of $\\mathbf{H}$ with corresponding eigenvalues in a diagonal matrix $\\mathbf{\\Lambda}$: the eigenvalue $\\mathbf{\\Lambda}_{i, i}$ corresponds to the eigenvector in the $i^{\\text{th}}$ column of $\\mathbf{S}$. The second derivative (curvature) of the objective function $f$ in any direction $\\mathbf{d}$ (unit vector) is a quadractic form $\\mathbf{d}^\\top \\mathbf{H} \\mathbf{d}$. Specifically, if the direction $\\mathbf{d}$ is an eigenvector of $\\mathbf{H}$, the curvature of $f$ in that direction is equal to the corresponding eigenvalue of $\\mathbf{d}$. Since the curvature of the objective function in any direction is a weighted average of all the eigenvalues of the Hesssian matrix, the curvature is bounded by the minimum and maximum eigenvalues of the Hesssian matrix $\\mathbf{H}$. The ratio of the maximum to the minimum eigenvalue is the **condition number** of the Hessian matrix $\\mathbf{H}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent in ill-conditioned problems\n",
    "\n",
    "How does the condition number of the Hessian matrix of the objective function affect the performance of gradient descent? Let us revisit the problem in the motivating example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that gradient descent is a greedy approach that selects the steepest gradient at the current point as the  direction of advancement. At the starting point, the search by gradient descent advances more aggressively in the direction of the $x_2$-axis than that of the $x_1$-axis. \n",
    "\n",
    "In the plotted problem of the motivating example, the curvature in the direction of the $x_2$-axis is much larger than that of the $x_1$-axis. Thus, gradient descent tends to overshoot the bottom of the function that is projected to the plane in parallel with the $x_2$-axis. At the next iteration, if the gradient along the direction in parallel with the $x_2$-axis remains larger, the search continues to advance more aggresively along the direction in parallel with the $x_2$-axis and the overshooting continues to take place. As a result, gradient descent wastes too much time swinging back and forth in parallel with the $x_2$-axis due to overshooting while the advancement in the direction of the $x_1$-axis is too slow.\n",
    "\n",
    "To generalize, the problem in the motivating example is an ill-conditioned problem. In an ill-conditioned problem, the condition number of the Hessian matrix of the objective function is large. In other words, the ratio of the largest curvature to the smallest is high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The momentum algorithm\n",
    "\n",
    "The aforementioned ill-conditioned problems are challenging for gradient descent. By treating gradient descent as a special form of stochastic gradient descent, we can address the challenge with the following momentum algorithm for stochastic gradient descent.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{v} &:= \\gamma \\mathbf{v} + \\eta \\nabla f_\\mathcal{B}(\\mathbf{x}),\\\\\n",
    "\\mathbf{x} &:= \\mathbf{x} - \\mathbf{v},\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{v}$ is the current velocity and $\\gamma$ is the momentum parameter. The learning rate $\\eta$ and the stochastic gradient $\\nabla f_\\mathcal{B}(\\mathbf{x})$ with respect to the sampled mini-batch $\\mathcal{B}$ are both defined in the [previous chapter](./gd-sgd.ipynb).\n",
    "\n",
    "It is important to highlight that, the scale of advancement at each iteration now also depends on how aligned the directions of the past gradients are. This scale is the largest when all the past gradients are perfectly aligned to the same direction. \n",
    "\n",
    "To better understand the momentum parameter $\\gamma$, let us simplify the scenario by assuming the stochastic gradients $\\nabla f_\\mathcal{B}(\\mathbf{x})$ are the same as $\\mathbf{g}$ throughout the iterations. Since all the gradients are perfectly aligned to the same direction, the momentum algorithm accelerates the advancement along the same direction of $\\mathbf{g}$ as\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{v}_1 &:= \\eta\\mathbf{g},\\\\\n",
    "\\mathbf{v}_2 &:= \\gamma \\mathbf{v}_1 + \\eta\\mathbf{g} = \\eta\\mathbf{g} (\\gamma + 1),\\\\\n",
    "\\mathbf{v}_3 &:= \\gamma \\mathbf{v}_2 + \\eta\\mathbf{g} = \\eta\\mathbf{g} (\\gamma^2 + \\gamma + 1),\\\\\n",
    "&\\ldots\\\\\n",
    "\\mathbf{v}_\\inf &:= \\frac{\\eta\\mathbf{g}}{1 - \\gamma}.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Thus, if $\\gamma = 0.99$, the final velocity is 100 times faster than that of the corresponding gradient descent where the gradient is $\\mathbf{g}$. \n",
    "\n",
    "Now with the momentum algorithm, a sample search path can be improved as illustrated in the following figure.\n",
    "\n",
    "![](../img/momentum-move.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "For demonstrating the momentum algorith,, we still use the regression problem in the [linear regression chapter](../chapter02_supervised-learning/linear-regression-scratch.ipynb) as a case study. Specifically, we investigate stochastic gradient descent with momentum.\n",
    "\n",
    "As usual, we import related libraries, generate the synthetic data, and construct the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import mxnet as mx\n",
    "from mxnet import autograd\n",
    "from mxnet import gluon\n",
    "import numpy as np\n",
    "\n",
    "X = np.random.randn(10000, 2)\n",
    "Y = 2 * X[:,0] - 3.4 * X[:,1] + 4.2 + .01 * np.random.normal(size=10000)\n",
    "\n",
    "ctx = mx.cpu()\n",
    "net = gluon.nn.Sequential()\n",
    "net.add(gluon.nn.Dense(1))\n",
    "net.collect_params().initialize()\n",
    "loss = gluon.loss.L2Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we specify the batch sizes and learning rates for stochastic gradient descent algorithms with momentum. Specifically, the momentum parameter is set to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_sizes = [1, 10, 100, 1000]\n",
    "learning_rates = [0.1, 0.1, 0.5, 0.5]\n",
    "momentum_param = 0.5\n",
    "\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to train the models and observe the inferred parameter values after the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 1 dense0_weight [ 2.00212836 -3.39304566]\n",
      "Batch size: 1 dense0_bias 4.20125\n",
      "Batch size: 10 dense0_weight [ 2.00067949 -3.40136981]\n",
      "Batch size: 10 dense0_bias 4.20053\n",
      "Batch size: 100 dense0_weight [ 2.00005388 -3.40086675]\n",
      "Batch size: 100 dense0_bias 4.19988\n",
      "Batch size: 1000 dense0_weight [ 2.00004411 -3.39969349]\n",
      "Batch size: 1000 dense0_bias 4.20037\n"
     ]
    }
   ],
   "source": [
    "for batch_size, learning_rate in zip(batch_sizes, learning_rates):\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'sgd',\n",
    "                            {'learning_rate': learning_rate,\n",
    "                            'momentum': momentum_param})\n",
    "    net.collect_params().initialize(mx.init.Xavier(magnitude=2.24),\n",
    "                                    ctx=ctx, force_reinit=True)\n",
    "    train_data = mx.io.NDArrayIter(X, Y, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        train_data.reset()\n",
    "        for i, batch in enumerate(train_data):\n",
    "            data = batch.data[0].as_in_context(ctx)\n",
    "            label = batch.label[0].as_in_context(ctx).reshape((-1, 1))\n",
    "            with autograd.record():\n",
    "                output = net(data)\n",
    "                mse = loss(output, label)\n",
    "            mse.backward()\n",
    "            trainer.step(data.shape[0])\n",
    "\n",
    "    for para_name, para_value in net.collect_params().items():\n",
    "        print(\"Batch size:\", batch_size, para_name,\n",
    "              para_value.data().asnumpy()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, all the investigated algorithms find the weight vector to be close to [2, -3.4] and the bias term to be close to 4.2 as specified in the synthetic data generation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
